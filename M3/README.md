# LAB - M2
https://jyywiki.cn/OS/2024/labs/M3.md  

## 思路
先make，再执行`complete.py`，就能进行一句话续写（单词个数在`gpt.c`的token limit参数）  
分析代码，基本是py子进程执行`gpt-64`并获取结果  

### 性能分析
使用perf分析性能瓶颈：
`perf record -g -- python3 complete.py` 
如果报错，可能要改perf_event_paranoid
`echo 1 | sudo tee /proc/sys/kernel/perf_event_paranoid`

查看分析结果：
`perf report`
发现主要是`matmul_forward`函数占用大部分：  
  Children      Self  Comman  Symbol
+   96.03%    95.32%  gpt-64  [.] matmul_forward
所以主要工作就是对该函数的并行优化

### 并行优化

使用课程提供的线程库  
比较疑惑的点是如何传递参数，因为给的线程库（thread.h）中，fn只接收一个代表线程序号的int参数  
实验参考建议使用线程池：
> 在这个实验中，你需要静态分配好线程 (例如 4 个 workers)，然后由这些线程完成计算任务。

#### 初步理解
每个worker相当于一个消费者，`matmul_forward`相当于一个生产者，1对4的关系。  
生产者等有空闲时生产，唤醒消费者（广播？），否则等待  
消费者等结束时唤醒生产者，进入等待  
使用链表存放消息？  

两个方法：
1. 生产者只顾生产，所有消息放在一个队列，消费者轮流消费即可
2. 生产者逐个生产，如果消费者全忙则等待

考虑到方法1队列可能开销较大，先用方法2  
一个难点仍然是如何传参

#### 再思考
应该用一个buffer（缓冲区）！  
上面的两个方法的区别仅仅是buffer的大小，方法1为无限大buffer，法2为0  
作为实验，设一个不太大的buffer比较合理，比如10  
  
buffer的空或满即为同步条件，控制生产者和消费者  
  
本实验的计算任务并非完全分散，而是分阶段的，下一阶段（下个函数）前需要把计算结果准备好  
写起来同步条件比课堂的例子稍复杂些  
但`pc-cv-broadcast.c`仍然值得仔细参考  

## 实现注意点
- 线程是在开始就创建好的，而不是边用边创（与go的习惯不同），因为有最大线程数限制（16）
- 线程的计算结果不能直接join得到，因为要不断复用（直接join线程就结束了），而要手动控制同步
- 本次实验有多处同步：
  - 生产和消费的等待同步（看缓冲区是否空或满）
  - 主线程`matmul_forward`函数退出时，需要等待子线程都计算完（代码中用了一个计数器`remaining`）
  - 所有工作结束，要发送同步信号给子线程，以退出线程并join（代码中用了`finished`变量）
- 代码中缓冲区通过环形数组实现，也可以通过链表等其他方式
- `calc`的参数没有用指针，考虑到指针在每次循环时都得malloc，可能开销较大；目前实现是都存在环形缓冲区中

## 遗留问题
- 因为线程库的fn无法传参，又实验要求无法改线程库，所以只能使用全局变量（有其他方法？
- 或者将线程库改为传void*参数？
- 不用广播，而分别用生产、消费的CV？
- remaining和buf_count能否合并？似乎不行
- 用信号量做的话会不会简单一些？
- 与`#pragma omp`的效率比较

## 其他解答
今年的新题，网上完全找不到
